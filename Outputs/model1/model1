2025-02-21 20:42:12,078 - INFO - ======== Starting Model Training ========
2025-02-21 20:42:12,078 - INFO - Loading dataset...
2025-02-21 20:42:12,594 - INFO - Dataset loaded successfully!
2025-02-21 20:42:12,594 - INFO - Initializing the model...
2025-02-21 20:42:12,665 - INFO - Model initialized with 291,013 trainable parameters
2025-02-21 20:42:12,665 - INFO - Model Architecture: 
MobileNetV2ForCIFAR8M(
  (mobilenet_v2): MobileNetV2(
    (features): Sequential(
      (0): Conv2dNormActivation(
        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
      )
      (1): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (classifier): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=512, out_features=512, bias=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=512, out_features=5, bias=True)
    )
  )
)
2025-02-21 20:42:12,665 - INFO - Starting training for 60 epochs...
2025-02-21 20:42:13,233 - INFO - Tr_Loss: 1.5347, val_loss: 1.4318, Tr_acc: 35.82857142857143, val_ac: 61.333333333333336
2025-02-21 20:42:13,450 - INFO - Tr_Loss: 1.3297, val_loss: 1.2549, Tr_acc: 64.57142857142857, val_ac: 73.73333333333333
2025-02-21 20:42:13,662 - INFO - Tr_Loss: 1.1551, val_loss: 1.0887, Tr_acc: 74.22857142857143, val_ac: 77.33333333333333
2025-02-21 20:42:13,845 - INFO - Tr_Loss: 0.9821, val_loss: 0.9379, Tr_acc: 78.57142857142857, val_ac: 78.66666666666667
2025-02-21 20:42:14,040 - INFO - Tr_Loss: 0.8403, val_loss: 0.8123, Tr_acc: 81.77142857142857, val_ac: 80.26666666666667
2025-02-21 20:42:14,226 - INFO - Tr_Loss: 0.7137, val_loss: 0.7120, Tr_acc: 83.88571428571429, val_ac: 82.0
2025-02-21 20:42:14,413 - INFO - Tr_Loss: 0.6285, val_loss: 0.6326, Tr_acc: 85.42857142857143, val_ac: 82.93333333333334
2025-02-21 20:42:14,609 - INFO - Tr_Loss: 0.5539, val_loss: 0.5703, Tr_acc: 87.31428571428572, val_ac: 84.13333333333334
2025-02-21 20:42:14,797 - INFO - Tr_Loss: 0.5000, val_loss: 0.5220, Tr_acc: 87.08571428571429, val_ac: 84.4
2025-02-21 20:42:14,993 - INFO - Tr_Loss: 0.4523, val_loss: 0.4837, Tr_acc: 88.05714285714286, val_ac: 84.53333333333333
2025-02-21 20:42:15,189 - INFO - Tr_Loss: 0.4210, val_loss: 0.4521, Tr_acc: 88.62857142857143, val_ac: 85.2
2025-02-21 20:42:15,377 - INFO - Tr_Loss: 0.3747, val_loss: 0.4263, Tr_acc: 90.28571428571429, val_ac: 86.13333333333334
2025-02-21 20:42:15,570 - INFO - Tr_Loss: 0.3520, val_loss: 0.4042, Tr_acc: 90.8, val_ac: 86.13333333333334
2025-02-21 20:42:15,763 - INFO - Tr_Loss: 0.3307, val_loss: 0.3853, Tr_acc: 90.97142857142858, val_ac: 86.26666666666667
2025-02-21 20:42:15,953 - INFO - Tr_Loss: 0.3178, val_loss: 0.3696, Tr_acc: 91.31428571428572, val_ac: 86.8
2025-02-21 20:42:16,145 - INFO - Tr_Loss: 0.2998, val_loss: 0.3556, Tr_acc: 91.88571428571429, val_ac: 87.33333333333333
2025-02-21 20:42:16,339 - INFO - Tr_Loss: 0.2817, val_loss: 0.3439, Tr_acc: 92.22857142857143, val_ac: 87.6
2025-02-21 20:42:16,563 - INFO - Tr_Loss: 0.2631, val_loss: 0.3331, Tr_acc: 92.74285714285715, val_ac: 87.86666666666666
2025-02-21 20:42:16,761 - INFO - Tr_Loss: 0.2508, val_loss: 0.3242, Tr_acc: 93.42857142857143, val_ac: 88.53333333333333
2025-02-21 20:42:16,958 - INFO - Tr_Loss: 0.2433, val_loss: 0.3165, Tr_acc: 93.42857142857143, val_ac: 88.53333333333333
2025-02-21 20:42:17,170 - INFO - Tr_Loss: 0.2283, val_loss: 0.3092, Tr_acc: 93.31428571428572, val_ac: 88.53333333333333
2025-02-21 20:42:17,379 - INFO - Tr_Loss: 0.2205, val_loss: 0.3029, Tr_acc: 93.6, val_ac: 88.93333333333334
2025-02-21 20:42:17,600 - INFO - Tr_Loss: 0.2073, val_loss: 0.2969, Tr_acc: 94.91428571428571, val_ac: 89.33333333333333
2025-02-21 20:42:17,788 - INFO - Tr_Loss: 0.1997, val_loss: 0.2916, Tr_acc: 94.22857142857143, val_ac: 89.6
2025-02-21 20:42:17,976 - INFO - Tr_Loss: 0.1883, val_loss: 0.2863, Tr_acc: 94.8, val_ac: 89.86666666666666
2025-02-21 20:42:18,177 - INFO - Tr_Loss: 0.1842, val_loss: 0.2818, Tr_acc: 94.85714285714286, val_ac: 90.0
2025-02-21 20:42:18,366 - INFO - Tr_Loss: 0.1766, val_loss: 0.2783, Tr_acc: 95.02857142857142, val_ac: 90.0
2025-02-21 20:42:18,561 - INFO - Tr_Loss: 0.1729, val_loss: 0.2751, Tr_acc: 95.37142857142857, val_ac: 90.53333333333333
2025-02-21 20:42:18,767 - INFO - Tr_Loss: 0.1597, val_loss: 0.2716, Tr_acc: 95.48571428571428, val_ac: 90.66666666666667
2025-02-21 20:42:18,969 - INFO - Tr_Loss: 0.1568, val_loss: 0.2687, Tr_acc: 95.82857142857142, val_ac: 90.93333333333334
2025-02-21 20:42:19,157 - INFO - Tr_Loss: 0.1434, val_loss: 0.2662, Tr_acc: 96.0, val_ac: 90.93333333333334
2025-02-21 20:42:19,346 - INFO - Tr_Loss: 0.1420, val_loss: 0.2634, Tr_acc: 96.4, val_ac: 91.06666666666666
2025-02-21 20:42:19,529 - INFO - Tr_Loss: 0.1337, val_loss: 0.2613, Tr_acc: 96.68571428571428, val_ac: 91.06666666666666
2025-02-21 20:42:19,720 - INFO - Tr_Loss: 0.1278, val_loss: 0.2595, Tr_acc: 96.74285714285715, val_ac: 91.2
2025-02-21 20:42:19,908 - INFO - Tr_Loss: 0.1258, val_loss: 0.2581, Tr_acc: 96.62857142857143, val_ac: 91.2
2025-02-21 20:42:20,092 - INFO - Tr_Loss: 0.1178, val_loss: 0.2560, Tr_acc: 96.8, val_ac: 91.33333333333333
2025-02-21 20:42:20,286 - INFO - Tr_Loss: 0.1174, val_loss: 0.2550, Tr_acc: 96.74285714285715, val_ac: 91.46666666666667
2025-02-21 20:42:20,472 - INFO - Tr_Loss: 0.1042, val_loss: 0.2532, Tr_acc: 97.82857142857142, val_ac: 91.46666666666667
2025-02-21 20:42:20,665 - INFO - Tr_Loss: 0.1036, val_loss: 0.2518, Tr_acc: 97.82857142857142, val_ac: 91.06666666666666
2025-02-21 20:42:20,854 - INFO - Tr_Loss: 0.1000, val_loss: 0.2511, Tr_acc: 97.71428571428571, val_ac: 91.2
2025-02-21 20:42:21,070 - INFO - Tr_Loss: 0.0980, val_loss: 0.2506, Tr_acc: 97.54285714285714, val_ac: 91.2
2025-02-21 20:42:21,286 - INFO - Tr_Loss: 0.0911, val_loss: 0.2500, Tr_acc: 98.0, val_ac: 91.2
2025-02-21 20:42:21,481 - INFO - Tr_Loss: 0.0898, val_loss: 0.2492, Tr_acc: 97.94285714285714, val_ac: 91.33333333333333
2025-02-21 20:42:21,666 - INFO - Tr_Loss: 0.0839, val_loss: 0.2487, Tr_acc: 98.34285714285714, val_ac: 91.33333333333333
2025-02-21 20:42:21,849 - INFO - Tr_Loss: 0.0796, val_loss: 0.2480, Tr_acc: 98.4, val_ac: 91.46666666666667
2025-02-21 20:42:22,038 - INFO - Tr_Loss: 0.0736, val_loss: 0.2475, Tr_acc: 98.97142857142858, val_ac: 91.33333333333333
2025-02-21 20:42:22,234 - INFO - Tr_Loss: 0.0719, val_loss: 0.2474, Tr_acc: 98.74285714285715, val_ac: 91.33333333333333
2025-02-21 20:42:22,421 - INFO - Tr_Loss: 0.0679, val_loss: 0.2473, Tr_acc: 98.97142857142858, val_ac: 91.33333333333333
2025-02-21 20:42:22,616 - INFO - Tr_Loss: 0.0649, val_loss: 0.2463, Tr_acc: 98.85714285714286, val_ac: 91.46666666666667
2025-02-21 20:42:22,803 - INFO - Tr_Loss: 0.0634, val_loss: 0.2463, Tr_acc: 98.85714285714286, val_ac: 91.33333333333333
2025-02-21 20:42:22,991 - INFO - Tr_Loss: 0.0641, val_loss: 0.2466, Tr_acc: 99.02857142857142, val_ac: 91.2
2025-02-21 20:42:23,200 - INFO - Tr_Loss: 0.0572, val_loss: 0.2469, Tr_acc: 99.2, val_ac: 91.33333333333333
2025-02-21 20:42:23,398 - INFO - Tr_Loss: 0.0575, val_loss: 0.2480, Tr_acc: 99.02857142857142, val_ac: 91.46666666666667
2025-02-21 20:42:23,590 - INFO - Tr_Loss: 0.0527, val_loss: 0.2477, Tr_acc: 99.31428571428572, val_ac: 91.6
2025-02-21 20:42:23,780 - INFO - Tr_Loss: 0.0527, val_loss: 0.2484, Tr_acc: 99.2, val_ac: 91.46666666666667
2025-02-21 20:42:23,973 - INFO - Tr_Loss: 0.0473, val_loss: 0.2491, Tr_acc: 99.71428571428571, val_ac: 91.6
2025-02-21 20:42:24,165 - INFO - Tr_Loss: 0.0445, val_loss: 0.2492, Tr_acc: 99.65714285714286, val_ac: 91.46666666666667
2025-02-21 20:42:24,358 - INFO - Tr_Loss: 0.0416, val_loss: 0.2503, Tr_acc: 99.82857142857142, val_ac: 91.46666666666667
2025-02-21 20:42:24,541 - INFO - Tr_Loss: 0.0437, val_loss: 0.2505, Tr_acc: 99.65714285714286, val_ac: 91.6
2025-02-21 20:42:24,739 - INFO - Tr_Loss: 0.0367, val_loss: 0.2513, Tr_acc: 99.82857142857142, val_ac: 91.6
2025-02-21 20:42:24,740 - INFO - Saving trained model and training results...
2025-02-21 20:42:25,144 - INFO - Starting model evaluation...
2025-02-21 20:42:25,175 - INFO - Test Loss: 0.2602
2025-02-21 20:42:25,175 - INFO - Test Accuracy: 90.60%
2025-02-21 20:42:25,175 - INFO - ======== Model Training Completed! ========
