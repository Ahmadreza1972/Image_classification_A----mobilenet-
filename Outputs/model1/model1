2025-02-25 21:45:24,147 - INFO - ======== Starting Model Training ========
2025-02-25 21:45:24,147 - INFO - Loading dataset...
2025-02-25 21:45:24,738 - INFO - Dataset loaded successfully!
2025-02-25 21:45:24,738 - INFO - Initializing the model...
2025-02-25 21:45:24,888 - INFO - Model initialized with 291,013 trainable parameters
2025-02-25 21:45:24,888 - INFO - Model Architecture: 
MobileNetV2ForCIFAR8M(
  (mobilenet_v2): MobileNetV2(
    (features): Sequential(
      (0): Conv2dNormActivation(
        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
      )
      (1): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (classifier): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=512, out_features=512, bias=True)
      (2): ReLU()
      (3): Dropout(p=0.8, inplace=False)
      (4): Linear(in_features=512, out_features=5, bias=True)
    )
  )
)
2025-02-25 21:45:24,888 - INFO - Starting training for 60 epochs...
2025-02-25 21:45:25,592 - INFO - Tr_Loss: 1.5880, val_loss: 1.4828, Tr_acc: 26.0, val_ac: 58.666666666666664
2025-02-25 21:45:25,838 - INFO - Tr_Loss: 1.4415, val_loss: 1.3440, Tr_acc: 44.285714285714285, val_ac: 74.26666666666667
2025-02-25 21:45:26,056 - INFO - Tr_Loss: 1.3104, val_loss: 1.2135, Tr_acc: 57.94285714285714, val_ac: 78.13333333333334
2025-02-25 21:45:26,268 - INFO - Tr_Loss: 1.1868, val_loss: 1.0882, Tr_acc: 66.05714285714286, val_ac: 79.86666666666666
2025-02-25 21:45:26,487 - INFO - Tr_Loss: 1.0840, val_loss: 0.9724, Tr_acc: 70.57142857142857, val_ac: 81.33333333333333
2025-02-25 21:45:26,705 - INFO - Tr_Loss: 0.9810, val_loss: 0.8709, Tr_acc: 73.71428571428571, val_ac: 81.73333333333333
2025-02-25 21:45:26,908 - INFO - Tr_Loss: 0.8710, val_loss: 0.7846, Tr_acc: 76.8, val_ac: 83.33333333333333
2025-02-25 21:45:27,109 - INFO - Tr_Loss: 0.8103, val_loss: 0.7125, Tr_acc: 77.31428571428572, val_ac: 84.93333333333334
2025-02-25 21:45:27,312 - INFO - Tr_Loss: 0.7402, val_loss: 0.6519, Tr_acc: 79.14285714285714, val_ac: 85.2
2025-02-25 21:45:27,507 - INFO - Tr_Loss: 0.6712, val_loss: 0.6003, Tr_acc: 81.65714285714286, val_ac: 85.86666666666666
2025-02-25 21:45:27,714 - INFO - Tr_Loss: 0.6268, val_loss: 0.5567, Tr_acc: 83.2, val_ac: 86.4
2025-02-25 21:45:27,930 - INFO - Tr_Loss: 0.5917, val_loss: 0.5211, Tr_acc: 83.48571428571428, val_ac: 86.8
2025-02-25 21:45:28,154 - INFO - Tr_Loss: 0.5500, val_loss: 0.4900, Tr_acc: 83.77142857142857, val_ac: 87.06666666666666
2025-02-25 21:45:28,375 - INFO - Tr_Loss: 0.5352, val_loss: 0.4634, Tr_acc: 84.97142857142858, val_ac: 87.46666666666667
2025-02-25 21:45:28,587 - INFO - Tr_Loss: 0.4952, val_loss: 0.4395, Tr_acc: 85.37142857142857, val_ac: 87.46666666666667
2025-02-25 21:45:28,798 - INFO - Tr_Loss: 0.4783, val_loss: 0.4201, Tr_acc: 85.6, val_ac: 88.13333333333334
2025-02-25 21:45:28,998 - INFO - Tr_Loss: 0.4604, val_loss: 0.4024, Tr_acc: 86.22857142857143, val_ac: 88.53333333333333
2025-02-25 21:45:29,193 - INFO - Tr_Loss: 0.4209, val_loss: 0.3874, Tr_acc: 86.85714285714286, val_ac: 88.93333333333334
2025-02-25 21:45:29,403 - INFO - Tr_Loss: 0.4109, val_loss: 0.3728, Tr_acc: 86.97142857142858, val_ac: 88.93333333333334
2025-02-25 21:45:29,591 - INFO - Tr_Loss: 0.3922, val_loss: 0.3597, Tr_acc: 88.45714285714286, val_ac: 89.6
2025-02-25 21:45:29,798 - INFO - Tr_Loss: 0.3810, val_loss: 0.3492, Tr_acc: 88.62857142857143, val_ac: 89.86666666666666
2025-02-25 21:45:30,006 - INFO - Tr_Loss: 0.3744, val_loss: 0.3396, Tr_acc: 88.45714285714286, val_ac: 89.86666666666666
2025-02-25 21:45:30,214 - INFO - Tr_Loss: 0.3532, val_loss: 0.3303, Tr_acc: 89.31428571428572, val_ac: 90.13333333333334
2025-02-25 21:45:30,405 - INFO - Tr_Loss: 0.3365, val_loss: 0.3220, Tr_acc: 89.94285714285714, val_ac: 90.26666666666667
2025-02-25 21:45:30,590 - INFO - Tr_Loss: 0.3244, val_loss: 0.3143, Tr_acc: 89.77142857142857, val_ac: 90.53333333333333
2025-02-25 21:45:30,786 - INFO - Tr_Loss: 0.3057, val_loss: 0.3071, Tr_acc: 90.91428571428571, val_ac: 90.66666666666667
2025-02-25 21:45:30,973 - INFO - Tr_Loss: 0.2995, val_loss: 0.3020, Tr_acc: 90.62857142857143, val_ac: 90.93333333333334
2025-02-25 21:45:31,159 - INFO - Tr_Loss: 0.2951, val_loss: 0.2965, Tr_acc: 90.74285714285715, val_ac: 91.06666666666666
2025-02-25 21:45:31,352 - INFO - Tr_Loss: 0.2785, val_loss: 0.2900, Tr_acc: 92.11428571428571, val_ac: 91.06666666666666
2025-02-25 21:45:31,538 - INFO - Tr_Loss: 0.2788, val_loss: 0.2847, Tr_acc: 91.42857142857143, val_ac: 91.06666666666666
2025-02-25 21:45:31,753 - INFO - Tr_Loss: 0.2590, val_loss: 0.2797, Tr_acc: 91.71428571428571, val_ac: 91.06666666666666
2025-02-25 21:45:32,034 - INFO - Tr_Loss: 0.2537, val_loss: 0.2764, Tr_acc: 92.62857142857143, val_ac: 91.33333333333333
2025-02-25 21:45:32,262 - INFO - Tr_Loss: 0.2514, val_loss: 0.2727, Tr_acc: 93.42857142857143, val_ac: 91.73333333333333
2025-02-25 21:45:32,471 - INFO - Tr_Loss: 0.2475, val_loss: 0.2701, Tr_acc: 92.8, val_ac: 91.6
2025-02-25 21:45:32,660 - INFO - Tr_Loss: 0.2352, val_loss: 0.2667, Tr_acc: 93.2, val_ac: 91.73333333333333
2025-02-25 21:45:32,876 - INFO - Tr_Loss: 0.2221, val_loss: 0.2626, Tr_acc: 93.82857142857142, val_ac: 91.86666666666666
2025-02-25 21:45:33,063 - INFO - Tr_Loss: 0.2239, val_loss: 0.2604, Tr_acc: 93.31428571428572, val_ac: 92.0
2025-02-25 21:45:33,261 - INFO - Tr_Loss: 0.2143, val_loss: 0.2573, Tr_acc: 93.6, val_ac: 91.86666666666666
2025-02-25 21:45:33,452 - INFO - Tr_Loss: 0.2138, val_loss: 0.2558, Tr_acc: 93.77142857142857, val_ac: 92.13333333333334
2025-02-25 21:45:33,659 - INFO - Tr_Loss: 0.2055, val_loss: 0.2543, Tr_acc: 93.82857142857142, val_ac: 92.13333333333334
2025-02-25 21:45:33,858 - INFO - Tr_Loss: 0.2000, val_loss: 0.2526, Tr_acc: 94.22857142857143, val_ac: 92.4
2025-02-25 21:45:34,047 - INFO - Tr_Loss: 0.1797, val_loss: 0.2505, Tr_acc: 94.74285714285715, val_ac: 92.4
2025-02-25 21:45:34,243 - INFO - Tr_Loss: 0.2016, val_loss: 0.2491, Tr_acc: 94.17142857142858, val_ac: 92.13333333333334
2025-02-25 21:45:34,453 - INFO - Tr_Loss: 0.1809, val_loss: 0.2458, Tr_acc: 94.4, val_ac: 92.26666666666667
2025-02-25 21:45:34,645 - INFO - Tr_Loss: 0.1778, val_loss: 0.2453, Tr_acc: 94.85714285714286, val_ac: 92.4
2025-02-25 21:45:34,832 - INFO - Tr_Loss: 0.1763, val_loss: 0.2444, Tr_acc: 94.8, val_ac: 92.26666666666667
2025-02-25 21:45:35,031 - INFO - Tr_Loss: 0.1704, val_loss: 0.2425, Tr_acc: 95.02857142857142, val_ac: 92.26666666666667
2025-02-25 21:45:35,221 - INFO - Tr_Loss: 0.1570, val_loss: 0.2404, Tr_acc: 95.54285714285714, val_ac: 92.4
2025-02-25 21:45:35,407 - INFO - Tr_Loss: 0.1472, val_loss: 0.2400, Tr_acc: 96.11428571428571, val_ac: 92.4
2025-02-25 21:45:35,598 - INFO - Tr_Loss: 0.1498, val_loss: 0.2389, Tr_acc: 95.94285714285714, val_ac: 92.4
2025-02-25 21:45:35,790 - INFO - Tr_Loss: 0.1440, val_loss: 0.2383, Tr_acc: 96.34285714285714, val_ac: 92.4
2025-02-25 21:45:35,978 - INFO - Tr_Loss: 0.1363, val_loss: 0.2389, Tr_acc: 96.68571428571428, val_ac: 92.4
2025-02-25 21:45:36,163 - INFO - Tr_Loss: 0.1395, val_loss: 0.2382, Tr_acc: 95.71428571428571, val_ac: 92.26666666666667
2025-02-25 21:45:36,354 - INFO - Tr_Loss: 0.1342, val_loss: 0.2367, Tr_acc: 96.11428571428571, val_ac: 92.13333333333334
2025-02-25 21:45:36,550 - INFO - Tr_Loss: 0.1367, val_loss: 0.2369, Tr_acc: 96.05714285714286, val_ac: 92.13333333333334
2025-02-25 21:45:36,731 - INFO - Tr_Loss: 0.1274, val_loss: 0.2376, Tr_acc: 96.74285714285715, val_ac: 92.4
2025-02-25 21:45:36,932 - INFO - Tr_Loss: 0.1240, val_loss: 0.2361, Tr_acc: 96.51428571428572, val_ac: 92.53333333333333
2025-02-25 21:45:37,145 - INFO - Tr_Loss: 0.1167, val_loss: 0.2350, Tr_acc: 96.91428571428571, val_ac: 92.4
2025-02-25 21:45:37,338 - INFO - Tr_Loss: 0.1099, val_loss: 0.2352, Tr_acc: 97.42857142857143, val_ac: 92.4
2025-02-25 21:45:37,532 - INFO - Tr_Loss: 0.1097, val_loss: 0.2357, Tr_acc: 97.54285714285714, val_ac: 92.4
2025-02-25 21:45:37,533 - INFO - Saving trained model and training results...
2025-02-25 21:45:37,941 - INFO - Starting model evaluation...
2025-02-25 21:45:37,972 - INFO - Test Loss: 0.2580
2025-02-25 21:45:37,972 - INFO - Test Accuracy: 91.00%
2025-02-25 21:45:37,972 - INFO - ======== Model Training Completed! ========
