2025-02-21 20:47:57,891 - INFO - ======== Starting Model Training ========
2025-02-21 20:47:57,891 - INFO - Loading dataset...
2025-02-21 20:47:58,401 - INFO - Dataset loaded successfully!
2025-02-21 20:47:58,401 - INFO - Initializing the model...
2025-02-21 20:47:58,473 - INFO - Model initialized with 291,013 trainable parameters.
2025-02-21 20:47:58,473 - INFO - Model Architecture: 
MobileNetV2ForCIFAR8M(
  (mobilenet_v2): MobileNetV2(
    (features): Sequential(
      (0): Conv2dNormActivation(
        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
      )
      (1): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (classifier): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=512, out_features=512, bias=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=512, out_features=5, bias=True)
    )
  )
)
2025-02-21 20:47:58,477 - INFO - Starting training for 40 epochs...
2025-02-21 20:47:59,016 - INFO - Tr_Loss: 1.5570, val_loss: 1.4791, Tr_acc: 29.942857142857143, val_ac: 44.4
2025-02-21 20:47:59,230 - INFO - Tr_Loss: 1.4247, val_loss: 1.3395, Tr_acc: 48.34285714285714, val_ac: 66.66666666666667
2025-02-21 20:47:59,435 - INFO - Tr_Loss: 1.2902, val_loss: 1.2113, Tr_acc: 65.02857142857142, val_ac: 74.66666666666667
2025-02-21 20:47:59,639 - INFO - Tr_Loss: 1.1727, val_loss: 1.0896, Tr_acc: 72.34285714285714, val_ac: 77.73333333333333
2025-02-21 20:47:59,833 - INFO - Tr_Loss: 1.0542, val_loss: 0.9768, Tr_acc: 75.02857142857142, val_ac: 79.06666666666666
2025-02-21 20:48:00,032 - INFO - Tr_Loss: 0.9427, val_loss: 0.8753, Tr_acc: 79.14285714285714, val_ac: 80.26666666666667
2025-02-21 20:48:00,248 - INFO - Tr_Loss: 0.8437, val_loss: 0.7868, Tr_acc: 80.45714285714286, val_ac: 81.6
2025-02-21 20:48:00,453 - INFO - Tr_Loss: 0.7590, val_loss: 0.7121, Tr_acc: 80.74285714285715, val_ac: 82.93333333333334
2025-02-21 20:48:00,651 - INFO - Tr_Loss: 0.6898, val_loss: 0.6498, Tr_acc: 83.31428571428572, val_ac: 83.33333333333333
2025-02-21 20:48:00,857 - INFO - Tr_Loss: 0.6242, val_loss: 0.5974, Tr_acc: 84.74285714285715, val_ac: 84.0
2025-02-21 20:48:01,060 - INFO - Tr_Loss: 0.5716, val_loss: 0.5541, Tr_acc: 84.8, val_ac: 84.8
2025-02-21 20:48:01,260 - INFO - Tr_Loss: 0.5234, val_loss: 0.5196, Tr_acc: 85.88571428571429, val_ac: 85.2
2025-02-21 20:48:01,461 - INFO - Tr_Loss: 0.4886, val_loss: 0.4899, Tr_acc: 86.34285714285714, val_ac: 85.6
2025-02-21 20:48:01,657 - INFO - Tr_Loss: 0.4566, val_loss: 0.4647, Tr_acc: 86.97142857142858, val_ac: 86.13333333333334
2025-02-21 20:48:01,866 - INFO - Tr_Loss: 0.4194, val_loss: 0.4434, Tr_acc: 88.51428571428572, val_ac: 86.13333333333334
2025-02-21 20:48:02,063 - INFO - Tr_Loss: 0.3896, val_loss: 0.4253, Tr_acc: 89.14285714285714, val_ac: 86.66666666666667
2025-02-21 20:48:02,267 - INFO - Tr_Loss: 0.3700, val_loss: 0.4096, Tr_acc: 89.77142857142857, val_ac: 86.53333333333333
2025-02-21 20:48:02,477 - INFO - Tr_Loss: 0.3472, val_loss: 0.3955, Tr_acc: 89.77142857142857, val_ac: 86.4
2025-02-21 20:48:02,673 - INFO - Tr_Loss: 0.3249, val_loss: 0.3832, Tr_acc: 90.68571428571428, val_ac: 87.06666666666666
2025-02-21 20:48:02,862 - INFO - Tr_Loss: 0.3158, val_loss: 0.3730, Tr_acc: 90.45714285714286, val_ac: 87.06666666666666
2025-02-21 20:48:03,045 - INFO - Tr_Loss: 0.2944, val_loss: 0.3632, Tr_acc: 91.65714285714286, val_ac: 87.6
2025-02-21 20:48:03,254 - INFO - Tr_Loss: 0.2765, val_loss: 0.3543, Tr_acc: 92.45714285714286, val_ac: 87.86666666666666
2025-02-21 20:48:03,465 - INFO - Tr_Loss: 0.2647, val_loss: 0.3474, Tr_acc: 92.4, val_ac: 88.13333333333334
2025-02-21 20:48:03,649 - INFO - Tr_Loss: 0.2574, val_loss: 0.3402, Tr_acc: 92.97142857142858, val_ac: 88.26666666666667
2025-02-21 20:48:03,847 - INFO - Tr_Loss: 0.2360, val_loss: 0.3339, Tr_acc: 94.11428571428571, val_ac: 88.4
2025-02-21 20:48:04,057 - INFO - Tr_Loss: 0.2283, val_loss: 0.3281, Tr_acc: 93.88571428571429, val_ac: 88.26666666666667
2025-02-21 20:48:04,251 - INFO - Tr_Loss: 0.2246, val_loss: 0.3230, Tr_acc: 93.54285714285714, val_ac: 88.66666666666667
2025-02-21 20:48:04,436 - INFO - Tr_Loss: 0.2060, val_loss: 0.3187, Tr_acc: 94.85714285714286, val_ac: 88.66666666666667
2025-02-21 20:48:04,623 - INFO - Tr_Loss: 0.1997, val_loss: 0.3141, Tr_acc: 94.17142857142858, val_ac: 88.8
2025-02-21 20:48:04,820 - INFO - Tr_Loss: 0.1929, val_loss: 0.3098, Tr_acc: 94.74285714285715, val_ac: 88.93333333333334
2025-02-21 20:48:05,005 - INFO - Tr_Loss: 0.1744, val_loss: 0.3059, Tr_acc: 95.6, val_ac: 89.2
2025-02-21 20:48:05,204 - INFO - Tr_Loss: 0.1760, val_loss: 0.3031, Tr_acc: 95.48571428571428, val_ac: 89.33333333333333
2025-02-21 20:48:05,398 - INFO - Tr_Loss: 0.1631, val_loss: 0.2999, Tr_acc: 95.88571428571429, val_ac: 89.33333333333333
2025-02-21 20:48:05,586 - INFO - Tr_Loss: 0.1634, val_loss: 0.2968, Tr_acc: 96.05714285714286, val_ac: 89.86666666666666
2025-02-21 20:48:05,805 - INFO - Tr_Loss: 0.1525, val_loss: 0.2952, Tr_acc: 96.68571428571428, val_ac: 89.73333333333333
2025-02-21 20:48:05,996 - INFO - Tr_Loss: 0.1438, val_loss: 0.2927, Tr_acc: 96.57142857142857, val_ac: 89.86666666666666
2025-02-21 20:48:06,181 - INFO - Tr_Loss: 0.1352, val_loss: 0.2913, Tr_acc: 96.85714285714286, val_ac: 89.73333333333333
2025-02-21 20:48:06,377 - INFO - Tr_Loss: 0.1340, val_loss: 0.2893, Tr_acc: 96.8, val_ac: 89.6
2025-02-21 20:48:06,569 - INFO - Tr_Loss: 0.1242, val_loss: 0.2871, Tr_acc: 97.08571428571429, val_ac: 89.86666666666666
2025-02-21 20:48:06,762 - INFO - Tr_Loss: 0.1201, val_loss: 0.2848, Tr_acc: 97.42857142857143, val_ac: 90.13333333333334
2025-02-21 20:48:06,762 - INFO - Saving trained model and training results...
2025-02-21 20:48:07,176 - INFO - Starting model evaluation...
2025-02-21 20:48:07,208 - INFO - Test Loss: 0.2619
2025-02-21 20:48:07,208 - INFO - Test Accuracy: 91.00%
2025-02-21 20:48:07,209 - INFO - ======== Model Training Completed! ========
