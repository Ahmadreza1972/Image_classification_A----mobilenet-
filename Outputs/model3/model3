2025-02-21 20:56:41,050 - INFO - ======== Starting Model Training ========
2025-02-21 20:56:41,050 - INFO - Loading dataset...
2025-02-21 20:56:41,550 - INFO - Dataset loaded successfully!
2025-02-21 20:56:41,550 - INFO - Initializing the model...
2025-02-21 20:56:41,625 - INFO - Model initialized with 291,013 trainable parameters.
2025-02-21 20:56:41,625 - INFO - Model Architecture: 
MobileNetV2ForCIFAR8M(
  (mobilenet_v2): MobileNetV2(
    (features): Sequential(
      (0): Conv2dNormActivation(
        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
      )
      (1): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (classifier): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=512, out_features=512, bias=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=512, out_features=5, bias=True)
    )
  )
)
2025-02-21 20:56:41,625 - INFO - Starting training for 80 epochs...
2025-02-21 20:56:42,146 - INFO - Tr_Loss: 1.5740, val_loss: 1.4988, Tr_acc: 28.742857142857144, val_ac: 46.53333333333333
2025-02-21 20:56:42,357 - INFO - Tr_Loss: 1.4343, val_loss: 1.3778, Tr_acc: 49.542857142857144, val_ac: 60.8
2025-02-21 20:56:42,575 - INFO - Tr_Loss: 1.3240, val_loss: 1.2633, Tr_acc: 60.22857142857143, val_ac: 66.4
2025-02-21 20:56:42,777 - INFO - Tr_Loss: 1.2109, val_loss: 1.1521, Tr_acc: 64.0, val_ac: 70.4
2025-02-21 20:56:42,975 - INFO - Tr_Loss: 1.1066, val_loss: 1.0484, Tr_acc: 69.94285714285714, val_ac: 73.33333333333333
2025-02-21 20:56:43,177 - INFO - Tr_Loss: 1.0028, val_loss: 0.9560, Tr_acc: 71.6, val_ac: 75.33333333333333
2025-02-21 20:56:43,385 - INFO - Tr_Loss: 0.9140, val_loss: 0.8766, Tr_acc: 74.91428571428571, val_ac: 76.13333333333334
2025-02-21 20:56:43,591 - INFO - Tr_Loss: 0.8361, val_loss: 0.8104, Tr_acc: 75.6, val_ac: 77.46666666666667
2025-02-21 20:56:43,786 - INFO - Tr_Loss: 0.7763, val_loss: 0.7557, Tr_acc: 77.65714285714286, val_ac: 79.06666666666666
2025-02-21 20:56:44,012 - INFO - Tr_Loss: 0.7271, val_loss: 0.7100, Tr_acc: 78.17142857142858, val_ac: 80.0
2025-02-21 20:56:44,212 - INFO - Tr_Loss: 0.6743, val_loss: 0.6719, Tr_acc: 79.94285714285714, val_ac: 80.53333333333333
2025-02-21 20:56:44,416 - INFO - Tr_Loss: 0.6306, val_loss: 0.6397, Tr_acc: 80.97142857142858, val_ac: 80.8
2025-02-21 20:56:44,611 - INFO - Tr_Loss: 0.5971, val_loss: 0.6124, Tr_acc: 81.88571428571429, val_ac: 81.73333333333333
2025-02-21 20:56:44,819 - INFO - Tr_Loss: 0.5628, val_loss: 0.5895, Tr_acc: 83.02857142857142, val_ac: 82.0
2025-02-21 20:56:45,030 - INFO - Tr_Loss: 0.5361, val_loss: 0.5693, Tr_acc: 83.31428571428572, val_ac: 82.4
2025-02-21 20:56:45,245 - INFO - Tr_Loss: 0.5126, val_loss: 0.5522, Tr_acc: 84.0, val_ac: 82.53333333333333
2025-02-21 20:56:45,452 - INFO - Tr_Loss: 0.4842, val_loss: 0.5371, Tr_acc: 85.65714285714286, val_ac: 82.53333333333333
2025-02-21 20:56:45,654 - INFO - Tr_Loss: 0.4619, val_loss: 0.5234, Tr_acc: 86.22857142857143, val_ac: 82.66666666666667
2025-02-21 20:56:45,879 - INFO - Tr_Loss: 0.4375, val_loss: 0.5114, Tr_acc: 86.11428571428571, val_ac: 82.53333333333333
2025-02-21 20:56:46,080 - INFO - Tr_Loss: 0.4190, val_loss: 0.5004, Tr_acc: 87.14285714285714, val_ac: 82.53333333333333
2025-02-21 20:56:46,270 - INFO - Tr_Loss: 0.4088, val_loss: 0.4911, Tr_acc: 87.42857142857143, val_ac: 82.4
2025-02-21 20:56:46,470 - INFO - Tr_Loss: 0.3909, val_loss: 0.4821, Tr_acc: 87.14285714285714, val_ac: 82.8
2025-02-21 20:56:46,694 - INFO - Tr_Loss: 0.3702, val_loss: 0.4743, Tr_acc: 88.62857142857143, val_ac: 82.93333333333334
2025-02-21 20:56:46,925 - INFO - Tr_Loss: 0.3613, val_loss: 0.4676, Tr_acc: 88.68571428571428, val_ac: 83.06666666666666
2025-02-21 20:56:47,146 - INFO - Tr_Loss: 0.3409, val_loss: 0.4611, Tr_acc: 89.25714285714285, val_ac: 83.2
2025-02-21 20:56:47,347 - INFO - Tr_Loss: 0.3274, val_loss: 0.4545, Tr_acc: 89.94285714285714, val_ac: 83.2
2025-02-21 20:56:47,539 - INFO - Tr_Loss: 0.3124, val_loss: 0.4497, Tr_acc: 91.02857142857142, val_ac: 83.46666666666667
2025-02-21 20:56:47,733 - INFO - Tr_Loss: 0.3058, val_loss: 0.4446, Tr_acc: 90.51428571428572, val_ac: 83.2
2025-02-21 20:56:47,965 - INFO - Tr_Loss: 0.2892, val_loss: 0.4404, Tr_acc: 91.25714285714285, val_ac: 83.33333333333333
2025-02-21 20:56:48,198 - INFO - Tr_Loss: 0.2730, val_loss: 0.4361, Tr_acc: 92.62857142857143, val_ac: 83.73333333333333
2025-02-21 20:56:48,438 - INFO - Tr_Loss: 0.2690, val_loss: 0.4326, Tr_acc: 92.22857142857143, val_ac: 83.73333333333333
2025-02-21 20:56:48,655 - INFO - Tr_Loss: 0.2610, val_loss: 0.4287, Tr_acc: 92.74285714285715, val_ac: 84.13333333333334
2025-02-21 20:56:48,884 - INFO - Tr_Loss: 0.2513, val_loss: 0.4257, Tr_acc: 93.14285714285714, val_ac: 83.86666666666666
2025-02-21 20:56:49,106 - INFO - Tr_Loss: 0.2479, val_loss: 0.4230, Tr_acc: 92.8, val_ac: 83.86666666666666
2025-02-21 20:56:49,323 - INFO - Tr_Loss: 0.2317, val_loss: 0.4200, Tr_acc: 93.77142857142857, val_ac: 84.26666666666667
2025-02-21 20:56:49,513 - INFO - Tr_Loss: 0.2219, val_loss: 0.4178, Tr_acc: 94.22857142857143, val_ac: 84.0
2025-02-21 20:56:49,710 - INFO - Tr_Loss: 0.2099, val_loss: 0.4153, Tr_acc: 95.08571428571429, val_ac: 84.0
2025-02-21 20:56:49,938 - INFO - Tr_Loss: 0.2010, val_loss: 0.4138, Tr_acc: 95.2, val_ac: 84.0
2025-02-21 20:56:50,166 - INFO - Tr_Loss: 0.1928, val_loss: 0.4113, Tr_acc: 95.08571428571429, val_ac: 84.26666666666667
2025-02-21 20:56:50,392 - INFO - Tr_Loss: 0.1894, val_loss: 0.4097, Tr_acc: 95.42857142857143, val_ac: 84.0
2025-02-21 20:56:50,611 - INFO - Tr_Loss: 0.1785, val_loss: 0.4086, Tr_acc: 95.82857142857142, val_ac: 84.26666666666667
2025-02-21 20:56:50,815 - INFO - Tr_Loss: 0.1743, val_loss: 0.4078, Tr_acc: 95.31428571428572, val_ac: 84.26666666666667
2025-02-21 20:56:51,035 - INFO - Tr_Loss: 0.1664, val_loss: 0.4075, Tr_acc: 96.62857142857143, val_ac: 84.66666666666667
2025-02-21 20:56:51,236 - INFO - Tr_Loss: 0.1574, val_loss: 0.4060, Tr_acc: 96.51428571428572, val_ac: 84.66666666666667
2025-02-21 20:56:51,441 - INFO - Tr_Loss: 0.1493, val_loss: 0.4049, Tr_acc: 97.14285714285714, val_ac: 84.66666666666667
2025-02-21 20:56:51,647 - INFO - Tr_Loss: 0.1476, val_loss: 0.4042, Tr_acc: 97.14285714285714, val_ac: 84.8
2025-02-21 20:56:51,848 - INFO - Tr_Loss: 0.1378, val_loss: 0.4034, Tr_acc: 97.54285714285714, val_ac: 84.93333333333334
2025-02-21 20:56:52,072 - INFO - Tr_Loss: 0.1319, val_loss: 0.4032, Tr_acc: 97.25714285714285, val_ac: 84.93333333333334
2025-02-21 20:56:52,302 - INFO - Tr_Loss: 0.1263, val_loss: 0.4044, Tr_acc: 97.71428571428571, val_ac: 84.93333333333334
2025-02-21 20:56:52,498 - INFO - Tr_Loss: 0.1215, val_loss: 0.4043, Tr_acc: 98.11428571428571, val_ac: 84.93333333333334
2025-02-21 20:56:52,735 - INFO - Tr_Loss: 0.1162, val_loss: 0.4033, Tr_acc: 97.94285714285714, val_ac: 85.06666666666666
2025-02-21 20:56:52,924 - INFO - Tr_Loss: 0.1070, val_loss: 0.4031, Tr_acc: 98.62857142857143, val_ac: 85.06666666666666
2025-02-21 20:56:53,117 - INFO - Tr_Loss: 0.1080, val_loss: 0.4033, Tr_acc: 98.22857142857143, val_ac: 85.06666666666666
2025-02-21 20:56:53,316 - INFO - Tr_Loss: 0.1025, val_loss: 0.4031, Tr_acc: 98.4, val_ac: 85.06666666666666
2025-02-21 20:56:53,511 - INFO - Tr_Loss: 0.0968, val_loss: 0.4041, Tr_acc: 98.62857142857143, val_ac: 85.33333333333333
2025-02-21 20:56:53,728 - INFO - Tr_Loss: 0.0921, val_loss: 0.4041, Tr_acc: 98.74285714285715, val_ac: 85.33333333333333
2025-02-21 20:56:53,960 - INFO - Tr_Loss: 0.0876, val_loss: 0.4068, Tr_acc: 98.74285714285715, val_ac: 85.33333333333333
2025-02-21 20:56:54,177 - INFO - Tr_Loss: 0.0839, val_loss: 0.4066, Tr_acc: 99.08571428571429, val_ac: 85.33333333333333
2025-02-21 20:56:54,405 - INFO - Tr_Loss: 0.0764, val_loss: 0.4068, Tr_acc: 99.25714285714285, val_ac: 85.2
2025-02-21 20:56:54,624 - INFO - Tr_Loss: 0.0747, val_loss: 0.4071, Tr_acc: 99.08571428571429, val_ac: 85.06666666666666
2025-02-21 20:56:54,832 - INFO - Tr_Loss: 0.0726, val_loss: 0.4080, Tr_acc: 99.37142857142857, val_ac: 85.33333333333333
2025-02-21 20:56:55,039 - INFO - Tr_Loss: 0.0688, val_loss: 0.4098, Tr_acc: 99.37142857142857, val_ac: 85.46666666666667
2025-02-21 20:56:55,260 - INFO - Tr_Loss: 0.0646, val_loss: 0.4097, Tr_acc: 99.31428571428572, val_ac: 85.2
2025-02-21 20:56:55,501 - INFO - Tr_Loss: 0.0602, val_loss: 0.4117, Tr_acc: 99.54285714285714, val_ac: 85.2
2025-02-21 20:56:55,731 - INFO - Tr_Loss: 0.0591, val_loss: 0.4135, Tr_acc: 99.71428571428571, val_ac: 85.2
2025-02-21 20:56:55,945 - INFO - Tr_Loss: 0.0548, val_loss: 0.4135, Tr_acc: 99.77142857142857, val_ac: 85.33333333333333
2025-02-21 20:56:56,183 - INFO - Tr_Loss: 0.0579, val_loss: 0.4145, Tr_acc: 99.54285714285714, val_ac: 85.33333333333333
2025-02-21 20:56:56,401 - INFO - Tr_Loss: 0.0527, val_loss: 0.4171, Tr_acc: 99.71428571428571, val_ac: 85.06666666666666
2025-02-21 20:56:56,601 - INFO - Tr_Loss: 0.0491, val_loss: 0.4171, Tr_acc: 99.71428571428571, val_ac: 85.33333333333333
2025-02-21 20:56:56,797 - INFO - Tr_Loss: 0.0492, val_loss: 0.4188, Tr_acc: 99.71428571428571, val_ac: 85.46666666666667
2025-02-21 20:56:56,996 - INFO - Tr_Loss: 0.0467, val_loss: 0.4199, Tr_acc: 99.82857142857142, val_ac: 85.46666666666667
2025-02-21 20:56:57,236 - INFO - Tr_Loss: 0.0445, val_loss: 0.4213, Tr_acc: 99.65714285714286, val_ac: 85.46666666666667
2025-02-21 20:56:57,459 - INFO - Tr_Loss: 0.0417, val_loss: 0.4231, Tr_acc: 100.0, val_ac: 85.46666666666667
2025-02-21 20:56:57,675 - INFO - Tr_Loss: 0.0393, val_loss: 0.4248, Tr_acc: 99.82857142857142, val_ac: 85.6
2025-02-21 20:56:57,890 - INFO - Tr_Loss: 0.0387, val_loss: 0.4262, Tr_acc: 99.82857142857142, val_ac: 85.46666666666667
2025-02-21 20:56:58,115 - INFO - Tr_Loss: 0.0336, val_loss: 0.4265, Tr_acc: 100.0, val_ac: 85.6
2025-02-21 20:56:58,333 - INFO - Tr_Loss: 0.0359, val_loss: 0.4283, Tr_acc: 100.0, val_ac: 85.46666666666667
2025-02-21 20:56:58,546 - INFO - Tr_Loss: 0.0318, val_loss: 0.4294, Tr_acc: 99.94285714285714, val_ac: 85.33333333333333
2025-02-21 20:56:58,743 - INFO - Tr_Loss: 0.0309, val_loss: 0.4310, Tr_acc: 100.0, val_ac: 85.33333333333333
2025-02-21 20:56:58,942 - INFO - Tr_Loss: 0.0325, val_loss: 0.4317, Tr_acc: 99.94285714285714, val_ac: 85.2
2025-02-21 20:56:58,942 - INFO - Saving trained model and training results...
2025-02-21 20:56:59,367 - INFO - Starting model evaluation...
2025-02-21 20:56:59,404 - INFO - Test Loss: 0.4108
2025-02-21 20:56:59,404 - INFO - Test Accuracy: 86.40%
2025-02-21 20:56:59,404 - INFO - ======== Model Training Completed! ========
